import React, { useState, useRef, useEffect } from "react";
import * as faceapi from "face-api.js";
import Title from "../components/Title";
import DnD from "../components/DnD";
import Button from "../components/Button";

function ImageEmotion() {
    const [imageSrc, setImageSrc] = useState(null); // Source de l'image ou photo captur√©e
    const [noFacesDetected, setNoFacesDetected] = useState(false); // √âtat pour afficher le message
    const [showCamera, setShowCamera] = useState(false); // √âtat pour afficher ou cacher la cam√©ra
    const videoRef = useRef(null); // R√©f√©rence pour la webcam
    const canvasRef = useRef(null); // R√©f√©rence pour le canvas d'analyse

    // Charger les mod√®les au montage du composant
    useEffect(() => {
        const loadModels = async () => {
            try {
                await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
                await faceapi.nets.faceLandmark68Net.loadFromUri("/models");
                await faceapi.nets.faceExpressionNet.loadFromUri("/models");
                console.log("Mod√®les charg√©s avec succ√®s.");
            } catch (err) {
                console.error("Erreur lors du chargement des mod√®les :", err);
            }
        };
        loadModels();
    }, []);

    const emotionTranslations = {
        happy: 'heureux üòä',
        sad: 'triste üò¢',
        angry: 'en col√®re üò°',
        surprised: 'surpris üò≤',
        neutral: 'neutre üòê',
        disgusted: 'd√©go√ªt√© ü§¢',
        fearful: 'peur üò±',
    };

    // Fonction pour analyser les √©motions sur une image
    const analyzeImage = async () => {
        if (imageSrc) {
            const image = document.getElementById("input-image");
            const canvas = canvasRef.current;
    
            // Ajuster les dimensions du canvas pour correspondre √† l'image
            canvas.width = image.naturalWidth; // Largeur native de l'image
            canvas.height = image.naturalHeight; // Hauteur native de l'image
    
            const detections = await faceapi
                .detectAllFaces(image, new faceapi.TinyFaceDetectorOptions())
                .withFaceLandmarks()
                .withFaceExpressions();
    
            if (detections.length === 0) {
                setNoFacesDetected(true); // Aucun visage d√©tect√©
                console.log("Aucun visage d√©tect√©.");
                return;
            } else {
                setNoFacesDetected(false); // Visage(s) d√©tect√©(s)
            }
    
            const displaySize = { width: image.naturalWidth, height: image.naturalHeight };
            faceapi.matchDimensions(canvas, displaySize);
    
            const resizedDetections = faceapi.resizeResults(detections, displaySize);
    
            const ctx = canvas.getContext("2d");
            ctx.clearRect(0, 0, canvas.width, canvas.height);
    
            faceapi.draw.drawDetections(canvas, resizedDetections);
            faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
    
            // Dessiner les √©motions traduites avec √©mojis
            resizedDetections.forEach((detection) => {
                const { x, y } = detection.detection.box;
                const expressions = detection.expressions;
    
                // Trier les √©motions par probabilit√© d√©croissante
                const sortedEmotions = Object.entries(expressions).sort(
                    (a, b) => b[1] - a[1]
                );
    
                // Prendre l'√©motion la plus probable
                const topEmotion = sortedEmotions[0];
                if (topEmotion) {
                    const [emotion, probability] = topEmotion;
                    const translatedEmotion =
                        emotionTranslations[emotion] || emotion; // Traduction ou garder l'original
                    ctx.font = "30px Arial";
                    ctx.fillStyle = "red";
                    ctx.fillText(
                        `${translatedEmotion} (${Math.round(probability * 100)}%)`,
                        x,
                        y - 30
                    );
                }
            });
        }
    };
    

    // Fonction pour activer la cam√©ra
    const startCamera = async () => {
        setShowCamera(true); // Afficher la cam√©ra
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            if (videoRef.current) {
                videoRef.current.srcObject = stream;
            }
        } catch (err) {
            console.error("Erreur lors de l'acc√®s √† la cam√©ra :", err);
        }
    };

    // Fonction pour capturer une photo
    const capturePhoto = async () => {
        if (videoRef.current) {
            const canvas = document.createElement("canvas");
            const video = videoRef.current;
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext("2d").drawImage(video, 0, 0, canvas.width, canvas.height);
            const dataUrl = canvas.toDataURL("image/png"); // Convertir en image
            setImageSrc(dataUrl); // Enregistrer la photo captur√©e
            setShowCamera(false); // Masquer la cam√©ra apr√®s la capture
            setNoFacesDetected(false); // R√©initialiser l'√©tat
        }
    };

    // Fonction pour r√©initialiser l'√©tat
    const reset = () => {
        setImageSrc(null); // Supprimer l'image captur√©e
        setNoFacesDetected(false); // R√©initialiser l'√©tat des visages
        setShowCamera(false); // R√©initialiser la cam√©ra
        if (videoRef.current && videoRef.current.srcObject) {
            const stream = videoRef.current.srcObject;
            const tracks = stream.getTracks(); // R√©cup√©rer les pistes de la cam√©ra
            tracks.forEach((track) => track.stop()); // Arr√™ter chaque piste
            videoRef.current.srcObject = null; // R√©initialiser la source vid√©o
        }
    };

    // Fonction pour g√©rer l'image d√©pos√©e
    const handleFileDrop = (file) => {
        if (file && file.type.startsWith("image/")) {
            const imageUrl = URL.createObjectURL(file);
            setImageSrc(imageUrl);
            setNoFacesDetected(false); // R√©initialiser l'√©tat
        } else {
            alert("Veuillez d√©poser un fichier image valide.");
        }
    };

    // Analyser l'image lorsque l'imageSrc change
    useEffect(() => {
        if (imageSrc) {
            analyzeImage();
        }
    }, [imageSrc]);

    return (
        <div className="main flex flex-col bg-black mt-10">
            <div className="min-h-screen flex justify-center items-center flex-col gap-15">
                <div className="h-dvh flex justify-center items-center flex-col">
                    <Title title="Image Emotion" />
                    <p className="text-white">Analyses les √©motions dans vos images ou capturez une photo !</p>
                    <DnD onFileDrop={handleFileDrop} />
                    <div id="image-preview">
                        {/* Activer la cam√©ra */}
                        {!showCamera && !imageSrc && (
                            <Button onClick={startCamera}>Activer la Cam√©ra</Button>
                        )}

                        {/* Vid√©o de la cam√©ra */}
                        {showCamera && (
                            <div className="flex flex-col items-center gap-5">
                                <video ref={videoRef} autoPlay muted></video>
                                <Button onClick={capturePhoto}>Prendre une Photo</Button>
                            </div>
                        )}

                        {/* Affiche l'image captur√©e ou d√©pos√©e */}
                        {imageSrc && (
                            <>
                                <div className="image-container">
                                    <img id="input-image" src={imageSrc} alt="Preview" />
                                    <canvas ref={canvasRef}></canvas>
                                </div>
                            </>
                        )}

                        {/* Message si aucun visage n'est d√©tect√© */}
                        {noFacesDetected && (
                            <div className="text-red-900 text-center">
                                <p>Aucun visage d√©tect√© dans cette image.</p>
                                <p>Veuillez mettre une image avec une meilleure qualit√© ou des visages plus proches.</p>
                            </div>
                        )}

                        {/* Bouton pour recommencer */}
                        {imageSrc && (
                            <div className="p-5">
                                <Button onClick={reset}>Recommencer</Button>
                            </div>
                        )}
                    </div>
                </div>
            </div>
        </div>
    );
}

export default ImageEmotion;
